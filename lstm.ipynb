{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from dataset_generator import TimeWindowDatasetGenerator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ppgValue</th>\n",
       "      <th>hr</th>\n",
       "      <th>hrIbi</th>\n",
       "      <th>hrStatus</th>\n",
       "      <th>ibiStatus</th>\n",
       "      <th>notification</th>\n",
       "      <th>engagement</th>\n",
       "      <th>affect</th>\n",
       "      <th>context</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12763</th>\n",
       "      <td>1</td>\n",
       "      <td>493272</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>3767.0</td>\n",
       "      <td>2103379.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12764</th>\n",
       "      <td>1</td>\n",
       "      <td>493311</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>2104145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>1</td>\n",
       "      <td>493351</td>\n",
       "      <td>894.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>3734.0</td>\n",
       "      <td>2104953.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12766</th>\n",
       "      <td>1</td>\n",
       "      <td>493391</td>\n",
       "      <td>907.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>2105398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12767</th>\n",
       "      <td>1</td>\n",
       "      <td>493431</td>\n",
       "      <td>861.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>2105114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101814</th>\n",
       "      <td>58</td>\n",
       "      <td>6184903</td>\n",
       "      <td>453.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>2126027.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101815</th>\n",
       "      <td>58</td>\n",
       "      <td>6184943</td>\n",
       "      <td>494.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>4059.0</td>\n",
       "      <td>2126361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101816</th>\n",
       "      <td>58</td>\n",
       "      <td>6184983</td>\n",
       "      <td>695.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>4124.0</td>\n",
       "      <td>2127234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101817</th>\n",
       "      <td>58</td>\n",
       "      <td>6185023</td>\n",
       "      <td>497.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>2128049.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101818</th>\n",
       "      <td>58</td>\n",
       "      <td>6185055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62898 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sessionId  timestamp      x       y       z   ppgValue  hr  hrIbi  \\\n",
       "12763            1     493272  884.0  1564.0  3767.0  2103379.0 NaN    NaN   \n",
       "12764            1     493311  900.0  1518.0  3782.0  2104145.0 NaN    NaN   \n",
       "12765            1     493351  894.0  1553.0  3734.0  2104953.0 NaN    NaN   \n",
       "12766            1     493391  907.0  1488.0  3729.0  2105398.0 NaN    NaN   \n",
       "12767            1     493431  861.0  1559.0  3731.0  2105114.0 NaN    NaN   \n",
       "...            ...        ...    ...     ...     ...        ...  ..    ...   \n",
       "8101814         58    6184903  453.0   552.0  4126.0  2126027.0 NaN    NaN   \n",
       "8101815         58    6184943  494.0   607.0  4059.0  2126361.0 NaN    NaN   \n",
       "8101816         58    6184983  695.0   841.0  4124.0  2127234.0 NaN    NaN   \n",
       "8101817         58    6185023  497.0   591.0  4329.0  2128049.0 NaN    NaN   \n",
       "8101818         58    6185055    NaN     NaN     NaN        NaN NaN    NaN   \n",
       "\n",
       "         hrStatus  ibiStatus  notification  engagement affect context  \\\n",
       "12763         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12764         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12765         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12766         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12767         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "...           ...        ...           ...         ...    ...     ...   \n",
       "8101814       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101815       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101816       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101817       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101818       NaN        NaN           NaN         NaN  HAPPY     NaN   \n",
       "\n",
       "         label_id    label  \n",
       "12763           1  RELAXED  \n",
       "12764           1  RELAXED  \n",
       "12765           1  RELAXED  \n",
       "12766           1  RELAXED  \n",
       "12767           1  RELAXED  \n",
       "...           ...      ...  \n",
       "8101814       240    HAPPY  \n",
       "8101815       240    HAPPY  \n",
       "8101816       240    HAPPY  \n",
       "8101817       240    HAPPY  \n",
       "8101818       240    HAPPY  \n",
       "\n",
       "[62898 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator = TimeWindowDatasetGenerator()\n",
    "labeled_data = data_generator.get_labelled_timewindow_dataframe(student_data_filepath='task/student_data.csv',\n",
    "                                                                time_window=10,\n",
    "                                                                label_feature='affect',\n",
    "                                                                exclude_after_notification=False,\n",
    "                                                                exclude_after_engagement=False)\n",
    "\n",
    "\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = labeled_data\n",
    "def replace_nan_hr(row):\n",
    "    if not pd.isna(row['hr']) and row['hrStatus'] != 1:  \n",
    "        mean_hr = df[(df['hrStatus'] == 1)]['hr'].median()\n",
    "        return mean_hr\n",
    "    return row['hr']\n",
    "def replace_nan_hrIbi(row):\n",
    "    if not pd.isna(row['hrIbi']) and row['ibiStatus'] != 0:  \n",
    "        mean_hr = df[(df['ibiStatus'] == 1)]['hrIbi'].median()\n",
    "        return mean_hr\n",
    "    return row['hrIbi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ppgValue</th>\n",
       "      <th>hr</th>\n",
       "      <th>hrIbi</th>\n",
       "      <th>hrStatus</th>\n",
       "      <th>ibiStatus</th>\n",
       "      <th>notification</th>\n",
       "      <th>engagement</th>\n",
       "      <th>affect</th>\n",
       "      <th>context</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12763</th>\n",
       "      <td>1</td>\n",
       "      <td>493272</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>3767.0</td>\n",
       "      <td>2103379.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12764</th>\n",
       "      <td>1</td>\n",
       "      <td>493311</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>2104145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>1</td>\n",
       "      <td>493351</td>\n",
       "      <td>894.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>3734.0</td>\n",
       "      <td>2104953.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12766</th>\n",
       "      <td>1</td>\n",
       "      <td>493391</td>\n",
       "      <td>907.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>2105398.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12767</th>\n",
       "      <td>1</td>\n",
       "      <td>493431</td>\n",
       "      <td>861.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>2105114.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101814</th>\n",
       "      <td>58</td>\n",
       "      <td>6184903</td>\n",
       "      <td>453.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>2126027.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101815</th>\n",
       "      <td>58</td>\n",
       "      <td>6184943</td>\n",
       "      <td>494.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>4059.0</td>\n",
       "      <td>2126361.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101816</th>\n",
       "      <td>58</td>\n",
       "      <td>6184983</td>\n",
       "      <td>695.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>4124.0</td>\n",
       "      <td>2127234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101817</th>\n",
       "      <td>58</td>\n",
       "      <td>6185023</td>\n",
       "      <td>497.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>2128049.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101818</th>\n",
       "      <td>58</td>\n",
       "      <td>6185055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62898 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sessionId  timestamp      x       y       z   ppgValue  hr  hrIbi  \\\n",
       "12763            1     493272  884.0  1564.0  3767.0  2103379.0 NaN    NaN   \n",
       "12764            1     493311  900.0  1518.0  3782.0  2104145.0 NaN    NaN   \n",
       "12765            1     493351  894.0  1553.0  3734.0  2104953.0 NaN    NaN   \n",
       "12766            1     493391  907.0  1488.0  3729.0  2105398.0 NaN    NaN   \n",
       "12767            1     493431  861.0  1559.0  3731.0  2105114.0 NaN    NaN   \n",
       "...            ...        ...    ...     ...     ...        ...  ..    ...   \n",
       "8101814         58    6184903  453.0   552.0  4126.0  2126027.0 NaN    NaN   \n",
       "8101815         58    6184943  494.0   607.0  4059.0  2126361.0 NaN    NaN   \n",
       "8101816         58    6184983  695.0   841.0  4124.0  2127234.0 NaN    NaN   \n",
       "8101817         58    6185023  497.0   591.0  4329.0  2128049.0 NaN    NaN   \n",
       "8101818         58    6185055    NaN     NaN     NaN        NaN NaN    NaN   \n",
       "\n",
       "         hrStatus  ibiStatus  notification  engagement affect context  \\\n",
       "12763         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12764         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12765         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12766         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12767         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "...           ...        ...           ...         ...    ...     ...   \n",
       "8101814       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101815       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101816       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101817       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101818       NaN        NaN           NaN         NaN  HAPPY     NaN   \n",
       "\n",
       "         label_id    label  \n",
       "12763           1  RELAXED  \n",
       "12764           1  RELAXED  \n",
       "12765           1  RELAXED  \n",
       "12766           1  RELAXED  \n",
       "12767           1  RELAXED  \n",
       "...           ...      ...  \n",
       "8101814       240    HAPPY  \n",
       "8101815       240    HAPPY  \n",
       "8101816       240    HAPPY  \n",
       "8101817       240    HAPPY  \n",
       "8101818       240    HAPPY  \n",
       "\n",
       "[62898 rows x 16 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data['hr'] = df.apply(replace_nan_hr, axis=1)\n",
    "labeled_data['hrIbi'] = df.apply(replace_nan_hrIbi, axis=1)\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are NaN values in the 'hr' column after filling. 19\n",
      "Number of NaN values in the 'hr' column after filling: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ppgValue</th>\n",
       "      <th>hr</th>\n",
       "      <th>hrIbi</th>\n",
       "      <th>hrStatus</th>\n",
       "      <th>ibiStatus</th>\n",
       "      <th>notification</th>\n",
       "      <th>engagement</th>\n",
       "      <th>affect</th>\n",
       "      <th>context</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12763</th>\n",
       "      <td>1</td>\n",
       "      <td>493272</td>\n",
       "      <td>884.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>3767.0</td>\n",
       "      <td>2103379.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12764</th>\n",
       "      <td>1</td>\n",
       "      <td>493311</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>3782.0</td>\n",
       "      <td>2104145.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>1</td>\n",
       "      <td>493351</td>\n",
       "      <td>894.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>3734.0</td>\n",
       "      <td>2104953.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12766</th>\n",
       "      <td>1</td>\n",
       "      <td>493391</td>\n",
       "      <td>907.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>2105398.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12767</th>\n",
       "      <td>1</td>\n",
       "      <td>493431</td>\n",
       "      <td>861.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>2105114.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>RELAXED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101814</th>\n",
       "      <td>58</td>\n",
       "      <td>6184903</td>\n",
       "      <td>453.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>2126027.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101815</th>\n",
       "      <td>58</td>\n",
       "      <td>6184943</td>\n",
       "      <td>494.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>4059.0</td>\n",
       "      <td>2126361.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101816</th>\n",
       "      <td>58</td>\n",
       "      <td>6184983</td>\n",
       "      <td>695.0</td>\n",
       "      <td>841.0</td>\n",
       "      <td>4124.0</td>\n",
       "      <td>2127234.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101817</th>\n",
       "      <td>58</td>\n",
       "      <td>6185023</td>\n",
       "      <td>497.0</td>\n",
       "      <td>591.0</td>\n",
       "      <td>4329.0</td>\n",
       "      <td>2128049.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101818</th>\n",
       "      <td>58</td>\n",
       "      <td>6185055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAPPY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240</td>\n",
       "      <td>HAPPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62898 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sessionId  timestamp      x       y       z   ppgValue    hr  hrIbi  \\\n",
       "12763            1     493272  884.0  1564.0  3767.0  2103379.0  95.0  649.0   \n",
       "12764            1     493311  900.0  1518.0  3782.0  2104145.0  95.0  649.0   \n",
       "12765            1     493351  894.0  1553.0  3734.0  2104953.0  95.0  649.0   \n",
       "12766            1     493391  907.0  1488.0  3729.0  2105398.0  95.0  649.0   \n",
       "12767            1     493431  861.0  1559.0  3731.0  2105114.0  95.0  649.0   \n",
       "...            ...        ...    ...     ...     ...        ...   ...    ...   \n",
       "8101814         58    6184903  453.0   552.0  4126.0  2126027.0  81.0  917.0   \n",
       "8101815         58    6184943  494.0   607.0  4059.0  2126361.0  81.0  917.0   \n",
       "8101816         58    6184983  695.0   841.0  4124.0  2127234.0  81.0  917.0   \n",
       "8101817         58    6185023  497.0   591.0  4329.0  2128049.0  81.0  917.0   \n",
       "8101818         58    6185055    NaN     NaN     NaN        NaN  81.0  917.0   \n",
       "\n",
       "         hrStatus  ibiStatus  notification  engagement affect context  \\\n",
       "12763         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12764         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12765         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12766         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "12767         NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "...           ...        ...           ...         ...    ...     ...   \n",
       "8101814       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101815       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101816       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101817       NaN        NaN           NaN         NaN    NaN     NaN   \n",
       "8101818       NaN        NaN           NaN         NaN  HAPPY     NaN   \n",
       "\n",
       "         label_id    label  \n",
       "12763           1  RELAXED  \n",
       "12764           1  RELAXED  \n",
       "12765           1  RELAXED  \n",
       "12766           1  RELAXED  \n",
       "12767           1  RELAXED  \n",
       "...           ...      ...  \n",
       "8101814       240    HAPPY  \n",
       "8101815       240    HAPPY  \n",
       "8101816       240    HAPPY  \n",
       "8101817       240    HAPPY  \n",
       "8101818       240    HAPPY  \n",
       "\n",
       "[62898 rows x 16 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data['hrIbi'].fillna(method='ffill', inplace=True)\n",
    "labeled_data['hr'].fillna(method='ffill', inplace=True)\n",
    "#labeled_data.groupby('hr').head()\n",
    "nan_in_hr=labeled_data['hr'].isna().any()\n",
    "nan_count_in_hr = labeled_data['hr'].isna().sum()\n",
    "if nan_in_hr:\n",
    "    print(\"There are NaN values in the 'hr' column after filling.\",nan_count_in_hr)\n",
    "\n",
    "if nan_count_in_hr > 0:\n",
    "    fill_value = 649\n",
    "    labeled_data.loc[labeled_data['hrIbi'].isna(), 'hrIbi'] = fill_value\n",
    "    labeled_data.loc[labeled_data['hr'].isna(), 'hr'] = 95\n",
    "\n",
    "print(\"Number of NaN values in the 'hr' column after filling:\", labeled_data['hrIbi'].isna().sum())\n",
    "\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "  \n",
    "    data = data.drop(columns=[ 'notification', 'engagement','context','affect','hrStatus','ibiStatus',])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    numerical_cols = ['ppgValue','x', 'y', 'z','hr','hrIbi']\n",
    "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols].ffill())\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ppgValue</th>\n",
       "      <th>hr</th>\n",
       "      <th>hrIbi</th>\n",
       "      <th>label_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12763</th>\n",
       "      <td>1</td>\n",
       "      <td>493272</td>\n",
       "      <td>0.769742</td>\n",
       "      <td>0.827824</td>\n",
       "      <td>0.279626</td>\n",
       "      <td>-0.198057</td>\n",
       "      <td>1.863799</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12764</th>\n",
       "      <td>1</td>\n",
       "      <td>493311</td>\n",
       "      <td>0.783048</td>\n",
       "      <td>0.800829</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>-0.194905</td>\n",
       "      <td>1.863799</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>1</td>\n",
       "      <td>493351</td>\n",
       "      <td>0.778058</td>\n",
       "      <td>0.821369</td>\n",
       "      <td>0.256091</td>\n",
       "      <td>-0.191581</td>\n",
       "      <td>1.863799</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12766</th>\n",
       "      <td>1</td>\n",
       "      <td>493391</td>\n",
       "      <td>0.788869</td>\n",
       "      <td>0.783223</td>\n",
       "      <td>0.252526</td>\n",
       "      <td>-0.189750</td>\n",
       "      <td>1.863799</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12767</th>\n",
       "      <td>1</td>\n",
       "      <td>493431</td>\n",
       "      <td>0.750615</td>\n",
       "      <td>0.824890</td>\n",
       "      <td>0.253952</td>\n",
       "      <td>-0.190918</td>\n",
       "      <td>1.863799</td>\n",
       "      <td>-0.108217</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101814</th>\n",
       "      <td>58</td>\n",
       "      <td>6184903</td>\n",
       "      <td>0.411319</td>\n",
       "      <td>0.233920</td>\n",
       "      <td>0.535653</td>\n",
       "      <td>-0.104877</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101815</th>\n",
       "      <td>58</td>\n",
       "      <td>6184943</td>\n",
       "      <td>0.445415</td>\n",
       "      <td>0.266198</td>\n",
       "      <td>0.487871</td>\n",
       "      <td>-0.103503</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101816</th>\n",
       "      <td>58</td>\n",
       "      <td>6184983</td>\n",
       "      <td>0.612568</td>\n",
       "      <td>0.403523</td>\n",
       "      <td>0.534227</td>\n",
       "      <td>-0.099911</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101817</th>\n",
       "      <td>58</td>\n",
       "      <td>6185023</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.256808</td>\n",
       "      <td>0.680426</td>\n",
       "      <td>-0.096558</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101818</th>\n",
       "      <td>58</td>\n",
       "      <td>6185055</td>\n",
       "      <td>0.447910</td>\n",
       "      <td>0.256808</td>\n",
       "      <td>0.680426</td>\n",
       "      <td>-0.096558</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.466064</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62898 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sessionId  timestamp         x         y         z  ppgValue  \\\n",
       "12763            1     493272  0.769742  0.827824  0.279626 -0.198057   \n",
       "12764            1     493311  0.783048  0.800829  0.290323 -0.194905   \n",
       "12765            1     493351  0.778058  0.821369  0.256091 -0.191581   \n",
       "12766            1     493391  0.788869  0.783223  0.252526 -0.189750   \n",
       "12767            1     493431  0.750615  0.824890  0.253952 -0.190918   \n",
       "...            ...        ...       ...       ...       ...       ...   \n",
       "8101814         58    6184903  0.411319  0.233920  0.535653 -0.104877   \n",
       "8101815         58    6184943  0.445415  0.266198  0.487871 -0.103503   \n",
       "8101816         58    6184983  0.612568  0.403523  0.534227 -0.099911   \n",
       "8101817         58    6185023  0.447910  0.256808  0.680426 -0.096558   \n",
       "8101818         58    6185055  0.447910  0.256808  0.680426 -0.096558   \n",
       "\n",
       "               hr     hrIbi  label_id  label  \n",
       "12763    1.863799 -0.108217         1      2  \n",
       "12764    1.863799 -0.108217         1      2  \n",
       "12765    1.863799 -0.108217         1      2  \n",
       "12766    1.863799 -0.108217         1      2  \n",
       "12767    1.863799 -0.108217         1      2  \n",
       "...           ...       ...       ...    ...  \n",
       "8101814 -0.056656  0.466064       240      1  \n",
       "8101815 -0.056656  0.466064       240      1  \n",
       "8101816 -0.056656  0.466064       240      1  \n",
       "8101817 -0.056656  0.466064       240      1  \n",
       "8101818 -0.056656  0.466064       240      1  \n",
       "\n",
       "[62898 rows x 10 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = preprocess_data(labeled_data)\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 259, 4)\n",
      "(240, 1)\n",
      "(240, 259, 1)\n",
      "(240, 259, 1)\n"
     ]
    }
   ],
   "source": [
    "grouped = processed_data.groupby('label_id')\n",
    "grouped_label =  processed_data.groupby('label')\n",
    "\n",
    "min = len(grouped.get_group(1))\n",
    "for i in range(len(grouped)-1):\n",
    "    if len(grouped.get_group(i+2))<min:\n",
    "        min = len(grouped.get_group(i+2))\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "Xa = []\n",
    "Xb = []\n",
    "for i in range(len(grouped)):\n",
    "    X.append(grouped.get_group(i+1)[[\"x\", \"y\", \"z\",\"ppgValue\"]][:min])\n",
    "    Y.append(grouped.get_group(i+1).iloc[0][[\"label\"]])\n",
    "    Xa.append(grouped.get_group(i+1)[[\"hr\"]][:min])\n",
    "    Xb.append(grouped.get_group(i+1)[[\"hrIbi\"]][:min])\n",
    "    \n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Xa = np.array(Xa)\n",
    "Xb = np.array(Xb)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Xa.shape)\n",
    "print(Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 259, 4)\n",
      "(216, 1)\n",
      "(24, 259, 4)\n",
      "(24, 1)\n",
      "(216, 259, 1)\n",
      "(24, 259, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test,Xa_train, Xa_test,Xb_train, Xb_test, Y_train, Y_test = train_test_split(X, Xa, Xb, Y, test_size=0.1, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "print(Xa_train.shape)\n",
    "print(Xa_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" model = Sequential()\\nmodel.add(LSTM(64,input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\\nmodel.add(LSTM(64))\\nmodel.add(Dense(256, activation='sigmoid'))\\nmodel.add(Dense(64, activation='sigmoid'))\\nmodel.add(Dense(4, activation='softmax'))\\nmodel.summary() \""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = Sequential()\n",
    "model.add(LSTM(64,input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" adam_optimizer = keras.optimizers.AdamW(learning_rate=0.0001)\\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy']) \""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" adam_optimizer = keras.optimizers.AdamW(learning_rate=0.0001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy']) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.1) '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.1) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Y_pred = model.predict(X_test)\\n\\nY_pred = np.argmax(Y_pred, axis=1)\\n\\nfrom sklearn.metrics import accuracy_score, classification_report\\n\\naccuracy = accuracy_score(Y_test, Y_pred)\\nprint(\"Accuracy:\", accuracy)\\n\\n# You can also print a classification report for more detailed evaluation metrics\\nprint(classification_report(Y_test, Y_pred)) '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Y_pred = model.predict(X_test)\n",
    "\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# You can also print a classification report for more detailed evaluation metrics\n",
    "print(classification_report(Y_test, Y_pred)) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Input Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsha/bbdc24-mlbananas/venv/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,664</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">259</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m259\u001b[0m, \u001b[38;5;34m4\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m259\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m17,664\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m33,024\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m259\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m259\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m2,080\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m2,080\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m36\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m36\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m36\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m104\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m36\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,616</span> (217.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,616\u001b[0m (217.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,616</span> (217.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,616\u001b[0m (217.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define two sets of inputs\n",
    "inputA = keras.Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "inputB = keras.Input(shape=(Xa_train.shape[1],))\n",
    "inputC = keras.Input(shape=(Xb_train.shape[1],))\n",
    "# the first branch operates on the first input\n",
    "x = LSTM(64,input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True)(inputA)\n",
    "x = LSTM(64)(x)\n",
    "x = Dense(8, activation=\"sigmoid\")(x)\n",
    "x = Dense(4, activation=\"sigmoid\")(x)\n",
    "x = keras.Model(inputs=inputA, outputs=x)\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(8, activation=\"sigmoid\")(inputB)\n",
    "y = Dense(4, activation=\"sigmoid\")(y)\n",
    "y = keras.Model(inputs=inputB, outputs=y)\n",
    "\n",
    "v = Dense(8, activation=\"sigmoid\")(inputC)\n",
    "v = Dense(4, activation=\"sigmoid\")(v)\n",
    "v = keras.Model(inputs=inputC, outputs=v)\n",
    "# combine the output of the two branches\n",
    "combined = keras.layers.concatenate([x.output, y.output, v.output])\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(8, activation=\"sigmoid\")(combined)\n",
    "z = Dense(4, activation=\"softmax\")(z)\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = keras.Model(inputs=[x.input, y.input, v.input], outputs=z)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.4221 - loss: 1.4084 - val_accuracy: 0.4545 - val_loss: 1.3854\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.4449 - loss: 1.4028 - val_accuracy: 0.4545 - val_loss: 1.3837\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5035 - loss: 1.3418 - val_accuracy: 0.4545 - val_loss: 1.3818\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4383 - loss: 1.3969 - val_accuracy: 0.4545 - val_loss: 1.3796\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4619 - loss: 1.3883 - val_accuracy: 0.4545 - val_loss: 1.3774\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4683 - loss: 1.3722 - val_accuracy: 0.4545 - val_loss: 1.3751\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4637 - loss: 1.3371 - val_accuracy: 0.4545 - val_loss: 1.3727\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4568 - loss: 1.3570 - val_accuracy: 0.4545 - val_loss: 1.3705\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.4288 - loss: 1.3714 - val_accuracy: 0.4545 - val_loss: 1.3683\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4253 - loss: 1.4134 - val_accuracy: 0.4545 - val_loss: 1.3662\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4807 - loss: 1.3434 - val_accuracy: 0.4545 - val_loss: 1.3641\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4406 - loss: 1.3515 - val_accuracy: 0.4545 - val_loss: 1.3617\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4802 - loss: 1.3423 - val_accuracy: 0.4545 - val_loss: 1.3597\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4832 - loss: 1.3354 - val_accuracy: 0.4545 - val_loss: 1.3572\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4719 - loss: 1.3424 - val_accuracy: 0.4545 - val_loss: 1.3546\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4612 - loss: 1.3139 - val_accuracy: 0.4545 - val_loss: 1.3521\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4161 - loss: 1.3665 - val_accuracy: 0.4545 - val_loss: 1.3499\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4498 - loss: 1.3228 - val_accuracy: 0.4545 - val_loss: 1.3481\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.4777 - loss: 1.2866 - val_accuracy: 0.4545 - val_loss: 1.3463\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4761 - loss: 1.3249 - val_accuracy: 0.4545 - val_loss: 1.3445\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4282 - loss: 1.3641 - val_accuracy: 0.4545 - val_loss: 1.3418\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4567 - loss: 1.3199 - val_accuracy: 0.4545 - val_loss: 1.3393\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4246 - loss: 1.3575 - val_accuracy: 0.4545 - val_loss: 1.3369\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4819 - loss: 1.3057 - val_accuracy: 0.4545 - val_loss: 1.3345\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.4748 - loss: 1.2920 - val_accuracy: 0.4545 - val_loss: 1.3317\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4568 - loss: 1.3300 - val_accuracy: 0.4545 - val_loss: 1.3289\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4630 - loss: 1.3017 - val_accuracy: 0.4545 - val_loss: 1.3257\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4357 - loss: 1.3084 - val_accuracy: 0.4545 - val_loss: 1.3229\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4753 - loss: 1.2997 - val_accuracy: 0.4545 - val_loss: 1.3208\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4423 - loss: 1.2950 - val_accuracy: 0.4545 - val_loss: 1.3183\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4651 - loss: 1.2683 - val_accuracy: 0.4545 - val_loss: 1.3162\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4724 - loss: 1.2773 - val_accuracy: 0.4545 - val_loss: 1.3142\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4440 - loss: 1.3057 - val_accuracy: 0.4545 - val_loss: 1.3122\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4331 - loss: 1.3153 - val_accuracy: 0.4545 - val_loss: 1.3099\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.4698 - loss: 1.2547 - val_accuracy: 0.4545 - val_loss: 1.3078\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4566 - loss: 1.2844 - val_accuracy: 0.4545 - val_loss: 1.3061\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5228 - loss: 1.2266 - val_accuracy: 0.4545 - val_loss: 1.3040\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4638 - loss: 1.2723 - val_accuracy: 0.4545 - val_loss: 1.3014\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4594 - loss: 1.2725 - val_accuracy: 0.4545 - val_loss: 1.2991\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4554 - loss: 1.2759 - val_accuracy: 0.4545 - val_loss: 1.2969\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4372 - loss: 1.2953 - val_accuracy: 0.4545 - val_loss: 1.2947\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.5026 - loss: 1.2193 - val_accuracy: 0.4545 - val_loss: 1.2929\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4576 - loss: 1.2653 - val_accuracy: 0.4545 - val_loss: 1.2909\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4794 - loss: 1.2398 - val_accuracy: 0.4545 - val_loss: 1.2890\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4633 - loss: 1.2345 - val_accuracy: 0.4545 - val_loss: 1.2870\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4944 - loss: 1.2201 - val_accuracy: 0.4545 - val_loss: 1.2855\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4609 - loss: 1.2520 - val_accuracy: 0.4545 - val_loss: 1.2841\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4425 - loss: 1.2715 - val_accuracy: 0.4545 - val_loss: 1.2820\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4463 - loss: 1.2480 - val_accuracy: 0.4545 - val_loss: 1.2801\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4673 - loss: 1.2584 - val_accuracy: 0.4545 - val_loss: 1.2788\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4823 - loss: 1.2036 - val_accuracy: 0.4545 - val_loss: 1.2773\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.4694 - loss: 1.2369 - val_accuracy: 0.4545 - val_loss: 1.2756\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4296 - loss: 1.2581 - val_accuracy: 0.4545 - val_loss: 1.2739\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4484 - loss: 1.2508 - val_accuracy: 0.4545 - val_loss: 1.2722\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4325 - loss: 1.2699 - val_accuracy: 0.4545 - val_loss: 1.2701\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4072 - loss: 1.2935 - val_accuracy: 0.4545 - val_loss: 1.2680\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4539 - loss: 1.2562 - val_accuracy: 0.4545 - val_loss: 1.2660\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4754 - loss: 1.2196 - val_accuracy: 0.4545 - val_loss: 1.2638\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4543 - loss: 1.2555 - val_accuracy: 0.4545 - val_loss: 1.2614\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4478 - loss: 1.2514 - val_accuracy: 0.4545 - val_loss: 1.2588\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4448 - loss: 1.2392 - val_accuracy: 0.4545 - val_loss: 1.2566\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.4817 - loss: 1.2008 - val_accuracy: 0.4545 - val_loss: 1.2547\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4513 - loss: 1.2295 - val_accuracy: 0.4545 - val_loss: 1.2528\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.3997 - loss: 1.2768 - val_accuracy: 0.4545 - val_loss: 1.2508\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4579 - loss: 1.2321 - val_accuracy: 0.4545 - val_loss: 1.2489\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4784 - loss: 1.1938 - val_accuracy: 0.4545 - val_loss: 1.2469\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4438 - loss: 1.2093 - val_accuracy: 0.4545 - val_loss: 1.2449\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4554 - loss: 1.2135 - val_accuracy: 0.4545 - val_loss: 1.2435\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4287 - loss: 1.2550 - val_accuracy: 0.4545 - val_loss: 1.2419\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4614 - loss: 1.1994 - val_accuracy: 0.4545 - val_loss: 1.2394\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4952 - loss: 1.1653 - val_accuracy: 0.4545 - val_loss: 1.2381\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4467 - loss: 1.1992 - val_accuracy: 0.4545 - val_loss: 1.2372\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4345 - loss: 1.2364 - val_accuracy: 0.4545 - val_loss: 1.2369\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4658 - loss: 1.1941 - val_accuracy: 0.4545 - val_loss: 1.2351\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4675 - loss: 1.1835 - val_accuracy: 0.4545 - val_loss: 1.2333\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4810 - loss: 1.1924 - val_accuracy: 0.4545 - val_loss: 1.2317\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.5018 - loss: 1.1620 - val_accuracy: 0.4545 - val_loss: 1.2285\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.4497 - loss: 1.1805 - val_accuracy: 0.4545 - val_loss: 1.2252\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4459 - loss: 1.1929 - val_accuracy: 0.4545 - val_loss: 1.2234\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4690 - loss: 1.1867 - val_accuracy: 0.4545 - val_loss: 1.2220\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4500 - loss: 1.1934 - val_accuracy: 0.4545 - val_loss: 1.2208\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4637 - loss: 1.1756 - val_accuracy: 0.4545 - val_loss: 1.2198\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4452 - loss: 1.2048 - val_accuracy: 0.4545 - val_loss: 1.2189\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4452 - loss: 1.2005 - val_accuracy: 0.4545 - val_loss: 1.2176\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.5010 - loss: 1.1393 - val_accuracy: 0.4545 - val_loss: 1.2155\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4460 - loss: 1.1619 - val_accuracy: 0.4545 - val_loss: 1.2138\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4247 - loss: 1.2096 - val_accuracy: 0.4545 - val_loss: 1.2125\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4799 - loss: 1.1501 - val_accuracy: 0.4545 - val_loss: 1.2108\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4468 - loss: 1.1630 - val_accuracy: 0.4545 - val_loss: 1.2079\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.4264 - loss: 1.2067 - val_accuracy: 0.4545 - val_loss: 1.2059\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4521 - loss: 1.1616 - val_accuracy: 0.4545 - val_loss: 1.2043\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4351 - loss: 1.1709 - val_accuracy: 0.4545 - val_loss: 1.2034\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.4713 - loss: 1.1535 - val_accuracy: 0.4545 - val_loss: 1.2027\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.5018 - loss: 1.1194 - val_accuracy: 0.4545 - val_loss: 1.2015\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4543 - loss: 1.1774 - val_accuracy: 0.4545 - val_loss: 1.2019\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4735 - loss: 1.1287 - val_accuracy: 0.4545 - val_loss: 1.2004\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.4319 - loss: 1.1763 - val_accuracy: 0.4545 - val_loss: 1.2000\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4704 - loss: 1.1441 - val_accuracy: 0.4545 - val_loss: 1.1981\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.5016 - loss: 1.0938 - val_accuracy: 0.4545 - val_loss: 1.1958\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.5073 - loss: 1.1075 - val_accuracy: 0.4545 - val_loss: 1.1939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb21c5ecfa0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train, Xa_train, Xb_train], Y_train, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "Accuracy: 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      1.00      0.77        15\n",
      "         2.0       0.00      0.00      0.00         8\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62        24\n",
      "   macro avg       0.21      0.33      0.26        24\n",
      "weighted avg       0.39      0.62      0.48        24\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsha/bbdc24-mlbananas/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/harsha/bbdc24-mlbananas/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/harsha/bbdc24-mlbananas/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict([X_test,Xa_test,Xb_test])\n",
    "\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# You can also print a classification report for more detailed evaluation metrics\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'InvocationException'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/bbdc24-mlbananas/venv/lib/python3.10/site-packages/pydot/core.py:1753\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     stdout_data, stderr_data, process \u001b[38;5;241m=\u001b[39m \u001b[43mcall_graphviz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m        \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworking_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/bbdc24-mlbananas/venv/lib/python3.10/site-packages/pydot/core.py:133\u001b[0m, in \u001b[0;36mcall_graphviz\u001b[0;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m program_with_args \u001b[38;5;241m=\u001b[39m [program] \u001b[38;5;241m+\u001b[39m arguments\n\u001b[0;32m--> 133\u001b[0m process \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogram_with_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworking_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m stdout_data, stderr_data \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/bbdc24-mlbananas/venv/lib/python3.10/site-packages/keras/src/utils/model_visualization.py:36\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Attempt to create an image of a blank graph\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# to check the pydot/graphviz installation.\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/bbdc24-mlbananas/venv/lib/python3.10/site-packages/pydot/core.py:1762\u001b[0m, in \u001b[0;36mDot.create\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1761\u001b[0m     args[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{prog}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not found in path.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(prog\u001b[38;5;241m=\u001b[39mprog)\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bbdc24-mlbananas/venv/lib/python3.10/site-packages/keras/src/utils/model_visualization.py:405\u001b[0m, in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, show_layer_activations, show_trainable, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(message)\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcheck_graphviz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    406\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must install graphviz \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(see instructions at https://graphviz.gitlab.io/download/) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor `plot_model` to work.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m     )\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython.core.magics.namespace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;66;03m# We don't raise an exception here in order to avoid crashing\u001b[39;00m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;66;03m# notebook tests where graphviz is not available.\u001b[39;00m\n",
      "File \u001b[0;32m~/bbdc24-mlbananas/venv/lib/python3.10/site-packages/keras/src/utils/model_visualization.py:38\u001b[0m, in \u001b[0;36mcheck_graphviz\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     pydot\u001b[38;5;241m.\u001b[39mDot\u001b[38;5;241m.\u001b[39mcreate(pydot\u001b[38;5;241m.\u001b[39mDot())\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[43mpydot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInvocationException\u001b[49m):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'InvocationException'"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e7f40af90bc2d2251a604f1fe6996d4639de289267cbca86e488c23998c9c3a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
